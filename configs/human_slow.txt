### TRAINING HYPERPARAMETERS -------------------
--run_train=1

# metadata flags
--save_model=dads
--save_freq=100
--record_freq=100
--vid_name=skill

# optimization hyperparmaters
--replay_buffer_capacity=100000

# (set clear_buffer_iter=1 for on-policy)
--clear_buffer_every_iter=1
--initial_collect_steps=0
--collect_steps=4000
--num_epochs=100000

# skill dynamics optimization hyperparameters
--skill_dyn_train_steps=32
--skill_dynamics_lr=3e-4
--skill_dyn_batch_size=256

# agent hyperparameters
--agent_gamma=0.995
--agent_lr=3e-4
--agent_entropy=0.1
--agent_train_steps=64
--agent_batch_size=256

# (optional, do not change for on-policy) relabelling or off-policy corrections
--skill_dynamics_relabel_type=importance_sampling
--num_samples_for_relabelling=1
--is_clip_eps=1.

# (optional) skills can be resampled within the episodes, relative to max_env_steps
--min_steps_before_resample=2000
--resample_prob=0.0

# (optional) configure skill dynamics training samples to be only from the current policy
--train_skill_dynamics_on_policy=0

### SHARED HYPERPARAMETERS ---------------------
--environment=Humanoid-v1
--max_env_steps=1000
--reduced_observation=0
# end to end learn with skill dyanmics
--learn_slow_feature=0
# separately learn slow features
--learn_feature_separ=1
--seed=0
--neg_k=100

# define the type of skills being learnt
--num_skills=5
--skill_type=cont_uniform
--random_skills=100

# number of skill-video evaluations
--num_evals=3

# (optional) policy, critic and skill dynamics
--hidden_layer_size=1024

# (optional) skill dynamics hyperparameters
--graph_type=separate
--num_components=4
--fix_variance=1
--normalize_data=0

# (optional) clip sampled actions
--action_clipping=1.

# (optional) debugging
--debug=0

### EVALUATION HYPERPARAMETERS -----------------
--run_eval=1

# MPC hyperparameters
--planning_horizon=1
--primitive_horizon=10
--num_candidate_sequences=50
--refine_steps=10
--mppi_gamma=10
--prior_type=normal
--smoothing_beta=0.9
--top_primitives=5


### (optional) ENVIRONMENT SPECIFIC HYPERPARAMETERS --------
# DKitty hyperparameters
--expose_last_action=1
--expose_upright=1
--robot_noise_ratio=0.0
--root_noise_ratio=0.0
--upright_threshold=0.95
--scale_root_position=1
--randomize_hfield=0.0

# DKitty/DClaw
--observation_omission_size=0

# Cube Manipulation hyperparameters
--randomized_initial_distribution=1
--horizontal_wrist_constraint=0.3
--vertical_wrist_constraint=1.0
